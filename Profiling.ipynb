{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m47-T8JxBcOe"
      },
      "source": [
        "# Profiling\n",
        "\n",
        "## Why profile?\n",
        "\n",
        "Profiling is the act of finding the demands placed on your computer when a piece of code is run and, preferably, localising the demands to specific sections of code. This is important when optimising as it allows you to find which parts of your code contribute to the demand you want to reduce and then target your optimisation efforts there.\n",
        "\n",
        "For instance, if ```function_1``` takes 99% of the runtime of your code and ```function2``` takes the rest, there is no point in optimising ```function2``` as even reducing the runtime to zero for that function would not produce a noticeable impact on the runtime of the code as a whole. Instead, optimising ```function1``` should be the priority.\n",
        "\n",
        "For this reason, when optimising a code, the first step is to profile it. This means the time you spend optimising your code will have most impact."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFnTlggDMezd"
      },
      "source": [
        "## Profiling Effectively\n",
        "\n",
        "### Profiling Runs\n",
        "\n",
        "In many cases, when profiling and optimising a large and complex code, it may not be practical to perform full-scale executions of the code. This may be because, for example, the code is designed to run on HPC resources but you're profiling on your desktop. You may need to profile a simplified or scaled-down problem.\n",
        "\n",
        "In addition, it may be that a code may be used in a number of different ways, such as performing many different kinds of simulation or analysing many different kinds of data set. It may be that the code can be run with a multitude of different options that will use different parts of the code. It may be that you need to develop a suite of cases to profile to get a measure of how the code performs in different scenarios.\n",
        "\n",
        "### Length of Profiling Runs\n",
        "\n",
        "If you profile the same bit of code twice, you may get noticeably different execution times for a number of reasons. The shorter the profiling run, the larger the fractional difference between runs is likely to be. This means that a code needs to run for at least a few seconds for profiling to produce meaningful results.\n",
        "\n",
        "However, running the code for a long time is not a good solution either. When optimising a code, you will typically want to profile it after each attempt to improve it, to see if the changes you made had the desired effect. This means you will want to profile the code many times. If each profiling run takes a long time, this will slow down your development cycle.\n",
        "\n",
        "As a result, it's often desirable to have a profiling run that is as short as possible while still producing meaningful results. Often, between 10s and 1 minute is a reasonable compromise, although this may vary depending on the code.\n",
        "\n",
        "### Profiling Effective - Takeaway\n",
        "\n",
        "There isn't a simple answer to ensure you get an effective profile of your code as it may be very problem-specific. You should try to think about what your code is doing and what you want to profile carefully and develop a strategy. Then repeat the profiling a few times to ensure the results remain the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaLje19Gq3gq"
      },
      "source": [
        "## Profiling Tools\n",
        "\n",
        "There are a number of different profiling tools available for use in Python. In this notebook, we will look at a sample of them - favouring ones which are simple to implement in a Jupyter Notebook. However, this list is far from exhaustive.\n",
        "\n",
        "The examples in this section relate to running this notebook in Colab. To run this notebook in Anaconda locally a different approach may be required in some cases. Many of the commands are also available from the command line when profiling a ```.py``` file. Again, a different approach will be required in this usage case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TktrHlmgq3gq"
      },
      "source": [
        "## Run-time Profiling\n",
        "\n",
        "Profiling the run-time of the code is probably one of the most important parts of profiling. In many cases, the amount of time the code takes to run is the most limiting factor when deciding if a particular simulation can be carried out on the available computational resources in a reasonable amount of time. There are several useful bits of useful information we can gather.\n",
        "\n",
        "### Timing Code\n",
        "\n",
        "We can manually time code using the ```time``` module. One simple way to use this module is to use the ```time.time()``` function to get the current time at the start and end of the code you want to time. This value is returned as a ```float``` representing the number of seconds since the start of the Unix epoch, which began on 1 January 1970. ```time``` is part of the standard library, so no installation is required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bttapowq3gr"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# Get the time at the start of the run\n",
        "start_time = time.time()\n",
        "\n",
        "# This is the code we want to time\n",
        "total = 0\n",
        "for i in range(1000000):\n",
        "    total = total + i\n",
        "print(total)\n",
        "\n",
        "# Get the time at the end of the run\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the total time of the run\n",
        "total_time = end_time - start_time\n",
        "print(total_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_-XgCucq3gs"
      },
      "source": [
        "The ```time``` module is very limited for profiling, however, as it involves modifying the source code manually, which is time-consuming and introduces a risk of accidentally leaving timing code in the final version of the code, or introducing bugs when adding or removing timing code. It also doesn't give a detailed breakdown of where the time is spent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiLBPKBsHejk"
      },
      "source": [
        "### Profiling By Function\n",
        "Profiling by function gives us a high-level idea of how often functions are called and how long those calls last. One way to do this is to import the ```cProfile``` module and run a function using the ```cProfile.run()``` function, providing a string argument which is the command used to invoke the function. ```cProfile``` is part of the Python standard library and so is available without installing any additional packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LYP3nG9NqdE"
      },
      "outputs": [],
      "source": [
        "# Import the cProfile module\n",
        "import cProfile\n",
        "\n",
        "def is_even(value):\n",
        "  if value%2 == 0:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def halve(value):\n",
        "  return value / 2\n",
        "\n",
        "def function_to_test(upper_value):\n",
        "  result = 0\n",
        "  for i in range(int(upper_value) +1):\n",
        "    if is_even(i):\n",
        "      result=result + halve(i)\n",
        "\n",
        "  print(result)\n",
        "\n",
        "# Call the cProfile.run() method with a string argument that is the call to the function you want to profile\n",
        "cProfile.run('function_to_test(1e7)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zN9diO3JslR-"
      },
      "source": [
        "The results show the total time spent running the code and the total number of function calls. Then, for each function, it shows:\n",
        "* ```ncalls```: the number of times the function was called.\n",
        "* ```tottime```: the total time spent in the function, excluding time spent in functions called by the function.\n",
        "* ```percall```: the time spent in the function per call, excluding time spent in functions called by the function.\n",
        "* ```cumtime```: the total time spent in the function, including time spent in functions called by the function.\n",
        "* ```percall```: the time spent in the function per call, including time spent in functions called by the function.\n",
        "* ```filename:lineno(function)```: the filename, line number and function name.\n",
        "\n",
        "There will normally be a number of functions which are not functions you are written or explicitly called. These are often called as part of how Python internally executes your code. They are normally not very consequential in terms of run-time and can often be ignored."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0LRJre2luKm"
      },
      "source": [
        "### Profiling By Line\n",
        "\n",
        "Sometimes, knowing that a code spends a lot of time executing a function doesn't provide enough granularity to know exactly which operations are costly. In these cases, there are several options for find out how much time the code spends executing each line. One example is the  [```line_profiler```](https://pypi.org/project/line-profiler/) module.\n",
        "\n",
        "The first two lines of the following cell install and load this module. The final line uses the line profiler to call the function ```function_to_test``` with a value of $10^6$ passed to the ```upper_value``` argument. The function ```is_even``` is specified as the function to be profiled.\n",
        "\n",
        "Running the below cell calls ```function_to_test``` and reports the number of times each line is executed, the length of each execution and the total and fraction of time spent on each line of the function being profiled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FgjFKqOlwcu"
      },
      "outputs": [],
      "source": [
        "#Install the relevant module\n",
        "%pip install line_profiler\n",
        "\n",
        "#Load the module\n",
        "%load_ext line_profiler\n",
        "\n",
        "def is_even(value):\n",
        "  if value%2 == 0:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def halve(value):\n",
        "  return value / 2\n",
        "\n",
        "def function_to_test(upper_value):\n",
        "  result = 0\n",
        "  for i in range(int(upper_value) +1):\n",
        "    if is_even(i):\n",
        "      result=result + halve(i)\n",
        "\n",
        "  print(\"The result is: \", result)\n",
        "\n",
        "#\"lprun\" invokes the line profiler\n",
        "#We specify \"is_even\" as the function we want to profile\n",
        "#\"function_to_test(1e6)\" specifies the command we want to be executed\n",
        "#This allows the performance of a function to be tested in a specified context\n",
        "%lprun -f is_even function_to_test(1e6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvFPtk-wAl7l"
      },
      "source": [
        "In Colab, the results will be presented in a pop-up. In Anaconda or VS Code, the results will be displayed in output below the cell. The output shows the ```timer_unit``` (we'll need this in a minute), the total time and, for each line of the profiled function:\n",
        "* ```Hits```: the number of times the line was executed.\n",
        "* ```Time```: the number of timer units spent on that line in total. You can find the total time by multiplying this by the \"Timer unit\" at the top of the output.\n",
        "* ```Per Hit```: the average number of timer units spent on that line per execution.\n",
        "* ```% Time```: the percentage of the total time spent on that line.\n",
        "* ```Line Contents```: the contents of the line."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_nFJJcEq3gu"
      },
      "source": [
        "### The Effects of Profiling on Run-time\n",
        "\n",
        "One important note when using any profiling technique is that it can impact the run-time and memory usage of the code. This is because tracking various aspects of performance can actually impact performance as more information needs to be collected. In the example below we run the same code with and without profiling to show the difference in run-time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnuf4vpdq3gu"
      },
      "outputs": [],
      "source": [
        "#Install the relevant module\n",
        "%pip install line_profiler\n",
        "\n",
        "#Load the module\n",
        "%load_ext line_profiler\n",
        "\n",
        "def a_long_loop():\n",
        "  total = 0\n",
        "  for i in range(1000000):\n",
        "    total = total + i\n",
        "\n",
        "# Time the code without the profiler\n",
        "start_time = time.time()\n",
        "a_long_loop()\n",
        "end_time = time.time()\n",
        "time_no_profiler = end_time - start_time\n",
        "\n",
        "# Time the code with the profiler\n",
        "start_time = time.time()\n",
        "%lprun -f a_long_loop a_long_loop()\n",
        "end_time = time.time()\n",
        "time_with_profiler = end_time - start_time\n",
        "\n",
        "print(\"Time without profiler: \", time_no_profiler)\n",
        "print(\"Time with profiler: \", time_with_profiler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oqzM2pmq3gv"
      },
      "source": [
        "This occurs because the profiler is running alongside your code, collecting data. This can significantly increase run-time, so do not be surprised if the code runs slower when profiling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPs8EDfN5xqI"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "The code in the cell below has a particular bottleneck that determines the bulk of the runtime of the code.\n",
        "\n",
        "Examine the code by eye and try to understand how it works, where the bottleneck might lie and what you might do to optimise it. Don't run or change the code at this point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyLG0ouo6lPj"
      },
      "outputs": [],
      "source": [
        "# The goal of this code is to print either \"X is is prime\" or \"X is not prime\" for every value of X between 1 and 1000\n",
        "\n",
        "import math\n",
        "\n",
        "# This method checks if \"value\" is prime and returns True if it is and False if it isn't\n",
        "def check_prime(value):\n",
        "  #Initially assume the value is prime\n",
        "  prime=True\n",
        "\n",
        "  # Loop over the values which value may be divisible by and check if it's a multiple of any of them\n",
        "  for i in range(2, int(math.sqrt(value))+1):\n",
        "    if value%i==0:\n",
        "      # If value is divisible by i, value%i will be zero, so set prime to false\n",
        "      prime=False\n",
        "\n",
        "  # Now we've checked if value is divisible by any of the values it might be divisible by, return prime\n",
        "  return prime\n",
        "\n",
        "# This function prints a message dependent on whether the given value is prime or not\n",
        "def print_value_prime(value):\n",
        "  if check_prime(value):\n",
        "    print(value, \" is prime\")\n",
        "  else:\n",
        "    print(value, \" is not prime\")\n",
        "\n",
        "def print_primes(max_value):\n",
        "# Loop over all numbers between 1 and max_value, printing if they're prime or not\n",
        "  for i in range(1, max_value+1):\n",
        "    print_value_prime(i)\n",
        "\n",
        "#Print whether values between 1 and 1000 are prime\n",
        "print_primes(1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjdISmjQB2jv"
      },
      "source": [
        "Use ```cProfile```  to work out which function this bottleneck lies in, then use ```line_profiler``` to work out which line(s) the bottleneck lies in. Does this match where you thought it might be by eye? Would it be worth performing the optimisations you came up with earlier?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fDhp3s5dCIzN"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "\n",
        "import math\n",
        "import cProfile\n",
        "\n",
        "%pip install line_profiler\n",
        "%load_ext line_profiler\n",
        "\n",
        "# This method checks if \"value\" is prime and returns True if it is and False if it isn't\n",
        "def check_prime(value):\n",
        "  #Initially assume the value is prime\n",
        "  prime=True\n",
        "\n",
        "  # Loop over the values which value may be divisible by and check if it's a multiple of any of them\n",
        "  for i in range(2, int(math.sqrt(value))+1):\n",
        "    if value%i==0:\n",
        "      # If value is divisible by i, value%i will be zero, so set prime to false\n",
        "      prime=False\n",
        "\n",
        "  # Now we've checked if value is divisible by any of the values it might be divisible by, return prime\n",
        "  return prime\n",
        "\n",
        "# This function prints a message dependent on whether the given value is prime or not\n",
        "def print_value_prime(value):\n",
        "  if check_prime(value):\n",
        "    print(value, \" is prime\")\n",
        "  else:\n",
        "    print(value, \" is not prime\")\n",
        "\n",
        "def print_primes(max_value):\n",
        "# Loop over all numbers between 1 and max_value, printing if they're prime or not\n",
        "  for i in range(1, max_value+1):\n",
        "    print_value_prime(i)\n",
        "\n",
        "#Print whether values between 1 and 1000 are prime\n",
        "cProfile.run(\"print_primes(1000)\")\n",
        "#%lprun -f print_value_prime print_primes(1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng3CXicOH3jM"
      },
      "source": [
        "## Memory Profiling\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WNcsJ9fIPis"
      },
      "source": [
        "It's also possible to profile the memory which is used by the code. The amount of memory used will change over time as the code runs and data is created and discarded. One meaningful measurement which can be made is the difference in the amount of memory used at two different points in the program. If the first point is the start of the program then this will give a good approximation of how much memory is in use at the second point. Often it will be desirable for the second point to be when the maximum memory is in use and this may take some experimentation to find.\n",
        "\n",
        "One example of a memory profiler in Python is [```pympler```](https://pympler.readthedocs.io/en/latest/index.html#). An example is found below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJ_uJ9MSgnfy"
      },
      "outputs": [],
      "source": [
        "#Install pympler using pip\n",
        "%pip install pympler\n",
        "\n",
        "#Import the relevant parts of pympler\n",
        "from pympler import summary, muppy\n",
        "\n",
        "#Get the first measure of the objects in memory\n",
        "sum1 = muppy.get_objects()\n",
        "\n",
        "#Create some new objects in memory\n",
        "list1=[]\n",
        "\n",
        "for i in range(100):\n",
        "  new_dict = {}\n",
        "  for j in range(100):\n",
        "    new_dict[j] = [1000+i*100+j]\n",
        "\n",
        "  list1.append(new_dict)\n",
        "\n",
        "#Get the second measure of the objects in memory\n",
        "sum2 = muppy.get_objects()\n",
        "\n",
        "#Print a comparison the two measure of the objects in memory\n",
        "summary.print_(summary.get_diff(summary.summarize(sum1), summary.summarize(sum2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T9KoAYfIO2L"
      },
      "source": [
        "The summary printed shows the change in the number of different types of object stored in memory and the change in the amount of memory allocated to each type of object. In the example above, we have created a list containing 100 dictionaries, each containing 100 lists with each list containing one unique integer. Note that there are also a small number of other values created. These may be created due to processes happening \"under the hood\". Given their small contribution to the total number of values stored, they're not very significant."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Profiling.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.15 ('test_env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "998c598e3f8b5486c29180bb3f739ee8eaa0ec4b90607f2e13f92ef575de7a6a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}